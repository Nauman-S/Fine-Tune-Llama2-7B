# Fine-Tune-Llama2-7B

## Assignment 7: Instruction Fine-Tuning of LLaMA-2-7B with PEFT (LoRA)

Please read the complete report: **[assignment7_report.pdf](assignment7_report.pdf)**

This repository contains the implementation and results for fine-tuning LLaMA-2-7B using Parameter-Efficient Fine-Tuning (LoRA) on the Dolly-15K dataset, including distributed training implementations (FSDP and DDP) and comprehensive evaluation on AlpacaEval 2 and MT-Bench.