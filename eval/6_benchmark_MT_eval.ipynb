{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "414f5410",
   "metadata": {
    "id": "414f5410"
   },
   "source": [
    "# MT-Bench Multi-Turn Dialogue Evaluation\n",
    "\n",
    "## Purpose\n",
    "This notebook implements **MT-Bench (FastChat)** evaluation to assess multi-turn dialogue quality of our fine-tuned LLaMA-2-7B model. This is the second critical benchmark required by [Assignment 7](../../tasks/Assignment7.md) to demonstrate the effectiveness of our LoRA fine-tuning approach on conversational capabilities.\n",
    "\n",
    "## Evaluation Context\n",
    "Following the complete fine-tuning pipeline:\n",
    "\n",
    "1. **[Baseline Model Evaluation](2_baseline_model.ipynb)** - Established baseline performance metrics\n",
    "2. **[Fine-tuning Process](3_finetuning.ipynb)** - LoRA fine-tuning on Dolly-15K dataset  \n",
    "3. **[Fine-tuned Model Testing](4_finetune_model.ipynb)** - Inference and testing with fine-tuned model\n",
    "4. **[AlpacaEval 2 Benchmark](5_benchmark_alpaca_eval.ipynb)** - Instruction-following quality assessment\n",
    "5. **This Notebook** - MT-Bench multi-turn dialogue evaluation\n",
    "6. **Final Report** - Comprehensive analysis and results\n",
    "\n",
    "## MT-Bench Framework\n",
    "- **Repository**: https://github.com/lm-sys/FastChat\n",
    "- **Purpose**: Multi-turn dialogue quality evaluation\n",
    "- **Dataset**: 80 multi-turn conversations across 8 categories\n",
    "- **Method**: GPT-4 as judge to evaluate conversation quality, helpfulness, and consistency\n",
    "- **Metrics**: Overall score, category-specific scores, consistency across turns\n",
    "\n",
    "## Expected Improvements\n",
    "After LoRA fine-tuning on Dolly-15K, we expect to see:\n",
    "- **Better conversation flow** - More coherent multi-turn interactions\n",
    "- **Improved consistency** - Maintains context across conversation turns\n",
    "- **Enhanced helpfulness** - More useful and relevant responses in conversations\n",
    "- **Better dialogue structure** - Proper conversation formatting and flow\n",
    "\n",
    "## Technical Implementation\n",
    "- **Model**: Fine-tuned LLaMA-2-7B with LoRA adapters\n",
    "- **Process**:\n",
    "  1. Load our fine-tuned model\n",
    "  2. Run MT-Bench evaluation dataset (80 multi-turn conversations)\n",
    "  3. Use GPT-4 as automated judge to evaluate conversation quality\n",
    "  4. Calculate overall and category-specific scores\n",
    "- **Comparison**: Fine-tuned vs. baseline model performance on multi-turn dialogue\n",
    "\n",
    "## Workflow\n",
    "1. **Load fine-tuned model** from saved LoRA adapters\n",
    "2. **Load MT-Bench dataset** (80 multi-turn conversations)\n",
    "3. **Run evaluation** using MT-Bench framework\n",
    "4. **Generate scores** for overall and category-specific performance\n",
    "5. **Compare results** with baseline model performance\n",
    "6. **Document metrics** for final report\n",
    "\n",
    "## Success Criteria\n",
    "- **Higher overall score** than baseline model on MT-Bench\n",
    "- **Improved category scores** across different conversation types\n",
    "- **Better consistency** in multi-turn conversations\n",
    "- **Clear evidence** of enhanced conversational capabilities\n",
    "\n",
    "## MT-Bench Categories\n",
    "The evaluation covers 8 conversation categories:\n",
    "1. **Writing** - Creative and technical writing tasks\n",
    "2. **Roleplay** - Character and scenario-based conversations\n",
    "3. **Reasoning** - Logical and mathematical reasoning\n",
    "4. **Math** - Mathematical problem solving\n",
    "5. **Coding** - Programming and code-related discussions\n",
    "6. **Extraction** - Information extraction tasks\n",
    "7. **STEM** - Science, technology, engineering, math\n",
    "8. **Humanities** - Social sciences, history, philosophy\n",
    "\n",
    "---\n",
    "**Note**: This evaluation is essential for demonstrating that our LoRA fine-tuning approach successfully improves the model's multi-turn conversational capabilities, complementing the instruction-following improvements shown in AlpacaEval 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T_3ZyQNlBalG",
   "metadata": {
    "id": "T_3ZyQNlBalG"
   },
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/lm-sys/FastChat.git\n",
    "!git clone https://github.com/lm-sys/FastChat.git\n",
    "%cd FastChat\n",
    "!pip install -e \".[model_worker,llm_judge]\"\n",
    "!pip install -U transformers peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fOfpU64YByLO",
   "metadata": {
    "id": "fOfpU64YByLO"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "import os\n",
    "from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ViRTxH0KB93-",
   "metadata": {
    "id": "ViRTxH0KB93-"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from huggingface_hub import login\n",
    "login(new_session=False)"
   ],
   "metadata": {
    "id": "WuPY27_YHR4j"
   },
   "id": "WuPY27_YHR4j",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IMqkRjKkCf0o",
   "metadata": {
    "id": "IMqkRjKkCf0o"
   },
   "outputs": [],
   "source": [
    "#Load the fine-tuned model\n",
    "model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "adapter_path = \"/content/drive/MyDrive/LLaMA2-Dolly-Training/results/final_lora_adapter\"\n",
    "print(f\"Loading Fine-Tuned LoRA adapter from: {adapter_path}...\")\n",
    "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_path)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "merged_model_path = \"/content/drive/MyDrive/LLaMA2-Dolly-Training/models/Llama-2-7b-hf-dolly-merged\"\n",
    "model = model.merge_and_unload()\n",
    "os.makedirs(merged_model_path, exist_ok=True)\n",
    "model.save_pretrained(merged_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_path)\n",
    "tokenizer.save_pretrained(merged_model_path)\n",
    "print(model)"
   ],
   "metadata": {
    "id": "A2R1zE0oIGF-"
   },
   "id": "A2R1zE0oIGF-",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "output_dir = \"/content/drive/MyDrive/LLaMA2-Dolly-Training/outputs\"\n",
    "base_model_path = \"/content/drive/MyDrive/LLaMA2-Dolly-Training/models/Llama-2-7b-hf\"\n",
    "merged_model_path = \"/content/drive/MyDrive/LLaMA2-Dolly-Training/models/Llama-2-7b-hf-dolly-merged\"\n",
    "\n",
    "model_id_finetuned = \"llama-2-7b-dolly-qlora\"\n",
    "default_answer_file_finetuned = f\"/content/FastChat/fastchat/llm_judge/data/mt_bench/model_answer/{model_id_finetuned}.jsonl\"\n",
    "gdrive_answer_file_finetuned = f\"{output_dir}/{model_id_finetuned}_mt_bench_answers.jsonl\"\n",
    "\n",
    "model_id_baseline = \"llama-2-7b-hf-baseline\"\n",
    "default_answer_file_baseline = f\"/content/FastChat/fastchat/llm_judge/data/mt_bench/model_answer/{model_id_baseline}.jsonl\"\n",
    "gdrive_answer_file_baseline = f\"{output_dir}/{model_id_baseline}_mt_bench_answers.jsonl\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "fastchat_judge_dir = \"/content/FastChat/fastchat/llm_judge\"\n",
    "os.chdir(fastchat_judge_dir)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "13slybsXKwo7"
   },
   "id": "13slybsXKwo7",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "!echo \"Generating MT-Bench answers for Fine-Tuned Model (${model_id_finetuned})...\"\n",
    "!python3 gen_model_answer.py --model-path \"{merged_model_path}\" --max-new-token 2048 --model-id \"{model_id_finetuned}\" --answer-file \"{gdrive_answer_file_finetuned}\"\n",
    "!echo \"âœ“ Fine-tuned answers generated to default path: {default_answer_file_finetuned}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "UOCk8FZwO-jm"
   },
   "id": "UOCk8FZwO-jm",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\\nGenerating MT-Bench answers for Baseline Model...\")\n",
    "!python3 gen_model_answer.py \\\n",
    "    --model-path \"{base_model_path}\" \\\n",
    "    --model-id \"{model_id_baseline}\" \\\n",
    "    --answer-file \"{gdrive_answer_file_baseline}\" \\\n",
    "    --max-new-token 2048"
   ],
   "metadata": {
    "id": "SqspyuFHAgVe"
   },
   "id": "SqspyuFHAgVe",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(gdrive_answer_file_baseline)\n",
    "print(gdrive_answer_file_finetuned)"
   ],
   "metadata": {
    "id": "NBFXodRdCeM8"
   },
   "id": "NBFXodRdCeM8",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}