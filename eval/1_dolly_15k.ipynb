{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f9aed65",
   "metadata": {
    "id": "7f9aed65"
   },
   "source": [
    "# Dolly-15K Dataset Analysis & Preprocessing\n",
    "\n",
    "## Objective\n",
    "Understand the Dolly-15K dataset structure and perform necessary preprocessing for LLaMA-2-7B fine-tuning.\n",
    "\n",
    "## Dataset Overview\n",
    "- **Source**: [databricks/databricks-dolly-15k](https://huggingface.co/datasets/databricks/databricks-dolly-15k)\n",
    "- **Size**: 15,011 instruction-following examples\n",
    "- **Format**: `instruction`, `context`, `response` fields\n",
    "- **Quality**: Human-generated, high-quality instruction-response pairs\n",
    "- **Purpose**: Supervised Fine-Tuning\n",
    "\n",
    "## üîß Preprocessing Tasks\n",
    "1. **Load and inspect dataset structure**\n",
    "2. **Data quality checks** (filter empty)\n",
    "3. **Format standardization** to match assignment requirements\n",
    "4. **Data splits** (80% train, 10% val, 10% test)\n",
    "5. **Tokenization analysis** for LLaMA-2 compatibility\n",
    "\n",
    "## üìã Expected Output Format\n",
    "```\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Response:\n",
    "{response}\n",
    "```\n",
    "\n",
    "## üìÅ Processed Dataset Storage\n",
    "**Files Created**:\n",
    "- `train.parquet` (12,008 examples - 80%)\n",
    "- `val.parquet` (1,501 examples - 10%)  \n",
    "- `test.parquet` (1,502 examples - 10%)\n",
    "\n",
    "**Access Link**: https://drive.google.com/drive/folders/1CXJHPZEYk-XOypqvg71-j4fkdEvkboct?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e52f2f6",
   "metadata": {
    "id": "2e52f2f6"
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55310cfe",
   "metadata": {
    "id": "55310cfe",
    "outputId": "feee932d-dd11-4d12-f730-7341be6dc2f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7d2cd6a1f84c10ab522c21230dc650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ff3a6bece849408929c6318aa28af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "databricks-dolly-15k.jsonl:   0%|          | 0.00/13.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80b25afa4484d5d9f57997f01497ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/15011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "databricks/databricks-dolly-15k has 15011 rows\n"
     ]
    }
   ],
   "source": [
    "dataset_name=\"databricks/databricks-dolly-15k\"\n",
    "\n",
    "dataset = load_dataset(dataset_name)\n",
    "dataset = dataset['train']\n",
    "row_count = dataset.num_rows\n",
    "instruction = dataset['instruction']\n",
    "context = dataset['context']\n",
    "response = dataset['response']\n",
    "category = dataset['category']\n",
    "\n",
    "assert len(instruction) == row_count\n",
    "assert len(context) == row_count\n",
    "assert len(response) == row_count\n",
    "assert len(category) == row_count\n",
    "\n",
    "print(\"{0} has {1} rows\".format(dataset_name, row_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "MU9ps5dSj6GR",
   "metadata": {
    "id": "MU9ps5dSj6GR",
    "outputId": "34ae1dad-e68d-4b2a-dd31-0dfd9183a0eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>instruction</th><th>context</th><th>response</th><th>category</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;When did Virgin Australia star‚Ä¶</td><td>&quot;Virgin Australia, the trading ‚Ä¶</td><td>&quot;Virgin Australia commenced ser‚Ä¶</td><td>&quot;closed_qa&quot;</td></tr><tr><td>&quot;Which is a species of fish? To‚Ä¶</td><td>&quot;&quot;</td><td>&quot;Tope&quot;</td><td>&quot;classification&quot;</td></tr><tr><td>&quot;Why can camels survive for lon‚Ä¶</td><td>&quot;&quot;</td><td>&quot;Camels use the fat in their hu‚Ä¶</td><td>&quot;open_qa&quot;</td></tr><tr><td>&quot;Alice&#x27;s parents have three dau‚Ä¶</td><td>&quot;&quot;</td><td>&quot;The name of the third daughter‚Ä¶</td><td>&quot;open_qa&quot;</td></tr><tr><td>&quot;When was Tomoaki Komorida born‚Ä¶</td><td>&quot;Komorida was born in Kumamoto ‚Ä¶</td><td>&quot;Tomoaki Komorida was born on J‚Ä¶</td><td>&quot;closed_qa&quot;</td></tr><tr><td>&quot;If I have more pieces at the t‚Ä¶</td><td>&quot;Stalemate is a situation in ch‚Ä¶</td><td>&quot;No. \n",
       "Stalemate is a drawn posi‚Ä¶</td><td>&quot;information_extraction&quot;</td></tr><tr><td>&quot;Given a reference text about L‚Ä¶</td><td>&quot;Lollapalooza /Àål…íl…ôp…ôÀàluÀêz…ô/ (‚Ä¶</td><td>&quot;Lollapalooze is an annual musi‚Ä¶</td><td>&quot;closed_qa&quot;</td></tr><tr><td>&quot;Who gave the UN the land in NY‚Ä¶</td><td>&quot;&quot;</td><td>&quot;John D Rockerfeller&quot;</td><td>&quot;open_qa&quot;</td></tr><tr><td>&quot;Why mobile is bad for human&quot;</td><td>&quot;&quot;</td><td>&quot;We are always engaged one phon‚Ä¶</td><td>&quot;brainstorming&quot;</td></tr><tr><td>&quot;Who was John Moses Browning?&quot;</td><td>&quot;John Moses Browning (January 2‚Ä¶</td><td>&quot;John Moses Browning is one of ‚Ä¶</td><td>&quot;information_extraction&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ instruction            ‚îÜ context                ‚îÜ response               ‚îÜ category              ‚îÇ\n",
       "‚îÇ ---                    ‚îÜ ---                    ‚îÜ ---                    ‚îÜ ---                   ‚îÇ\n",
       "‚îÇ str                    ‚îÜ str                    ‚îÜ str                    ‚îÜ str                   ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ When did Virgin        ‚îÜ Virgin Australia, the  ‚îÜ Virgin Australia       ‚îÜ closed_qa             ‚îÇ\n",
       "‚îÇ Australia star‚Ä¶        ‚îÜ trading ‚Ä¶              ‚îÜ commenced ser‚Ä¶         ‚îÜ                       ‚îÇ\n",
       "‚îÇ Which is a species of  ‚îÜ                        ‚îÜ Tope                   ‚îÜ classification        ‚îÇ\n",
       "‚îÇ fish? To‚Ä¶              ‚îÜ                        ‚îÜ                        ‚îÜ                       ‚îÇ\n",
       "‚îÇ Why can camels survive ‚îÜ                        ‚îÜ Camels use the fat in  ‚îÜ open_qa               ‚îÇ\n",
       "‚îÇ for lon‚Ä¶               ‚îÜ                        ‚îÜ their hu‚Ä¶              ‚îÜ                       ‚îÇ\n",
       "‚îÇ Alice's parents have   ‚îÜ                        ‚îÜ The name of the third  ‚îÜ open_qa               ‚îÇ\n",
       "‚îÇ three dau‚Ä¶             ‚îÜ                        ‚îÜ daughter‚Ä¶              ‚îÜ                       ‚îÇ\n",
       "‚îÇ When was Tomoaki       ‚îÜ Komorida was born in   ‚îÜ Tomoaki Komorida was   ‚îÜ closed_qa             ‚îÇ\n",
       "‚îÇ Komorida born‚Ä¶         ‚îÜ Kumamoto ‚Ä¶             ‚îÜ born on J‚Ä¶             ‚îÜ                       ‚îÇ\n",
       "‚îÇ If I have more pieces  ‚îÜ Stalemate is a         ‚îÜ No.                    ‚îÜ information_extractio ‚îÇ\n",
       "‚îÇ at the t‚Ä¶              ‚îÜ situation in ch‚Ä¶       ‚îÜ Stalemate is a drawn   ‚îÜ n                     ‚îÇ\n",
       "‚îÇ                        ‚îÜ                        ‚îÜ posi‚Ä¶                  ‚îÜ                       ‚îÇ\n",
       "‚îÇ Given a reference text ‚îÜ Lollapalooza           ‚îÜ Lollapalooze is an     ‚îÜ closed_qa             ‚îÇ\n",
       "‚îÇ about L‚Ä¶               ‚îÜ /Àål…íl…ôp…ôÀàluÀêz…ô/ (‚Ä¶     ‚îÜ annual musi‚Ä¶           ‚îÜ                       ‚îÇ\n",
       "‚îÇ Who gave the UN the    ‚îÜ                        ‚îÜ John D Rockerfeller    ‚îÜ open_qa               ‚îÇ\n",
       "‚îÇ land in NY‚Ä¶            ‚îÜ                        ‚îÜ                        ‚îÜ                       ‚îÇ\n",
       "‚îÇ Why mobile is bad for  ‚îÜ                        ‚îÜ We are always engaged  ‚îÜ brainstorming         ‚îÇ\n",
       "‚îÇ human                  ‚îÜ                        ‚îÜ one phon‚Ä¶              ‚îÜ                       ‚îÇ\n",
       "‚îÇ Who was John Moses     ‚îÜ John Moses Browning    ‚îÜ John Moses Browning is ‚îÜ information_extractio ‚îÇ\n",
       "‚îÇ Browning?              ‚îÜ (January 2‚Ä¶            ‚îÜ one of ‚Ä¶               ‚îÜ n                     ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.DataFrame({\n",
    "    'instruction': instruction,\n",
    "    'context': context,\n",
    "    'response': response,\n",
    "    'category': category\n",
    "})\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "KDRoyYEHnHfW",
   "metadata": {
    "id": "KDRoyYEHnHfW",
    "outputId": "15d29b52-46a7-402e-b608-72c1785d619c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty instructions: 0\n",
      "Empty contexts: 10544 (70.2%)\n",
      "Empty responses: 0\n",
      "Empty categories: 0\n",
      "Removed 0 examples with empty responses\n",
      "Cleaned dataset size: 15011\n"
     ]
    }
   ],
   "source": [
    "empty_instructions = df.filter(pl.col('instruction').str.strip_chars() == '').height\n",
    "empty_contexts = df.filter(pl.col('context').str.strip_chars() == '').height\n",
    "empty_responses = df.filter(pl.col('response').str.strip_chars() == '').height\n",
    "empty_categories = df.filter(pl.col('category').str.strip_chars() == '').height\n",
    "\n",
    "print(f\"Empty instructions: {empty_instructions}\")\n",
    "print(f\"Empty contexts: {empty_contexts} ({empty_contexts/len(df)*100:.1f}%)\")\n",
    "print(f\"Empty responses: {empty_responses}\")\n",
    "print(f\"Empty categories: {empty_categories}\")\n",
    "\n",
    "df_cleaned = df.filter(pl.col('response').str.strip_chars() != '')\n",
    "removed_count = df.height - df_cleaned.height\n",
    "\n",
    "print(f\"Removed {removed_count} examples with empty responses\")\n",
    "print(f\"Cleaned dataset size: {df_cleaned.height}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "zjJGy-_iqL0j",
   "metadata": {
    "id": "zjJGy-_iqL0j",
    "outputId": "75574ec3-3637-4f45-9935-cfebacc6bc01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "When did Virgin Australia start operating?\n",
      "\n",
      "### Context:\n",
      "Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\n",
      "\n",
      "### Response:\n",
      "Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.\n"
     ]
    }
   ],
   "source": [
    "def format_instruction_template(instruction: str, context: str, response: str) -> str:\n",
    "    instruction = instruction.strip()\n",
    "    context = context.strip() if context else \"\"\n",
    "    response = response.strip()\n",
    "\n",
    "    if context:\n",
    "        return f\"\"\"### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Response:\n",
    "{response}\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "{response}\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "df = df.with_columns([\n",
    "    pl.struct(['instruction', 'context', 'response'])\n",
    "      .map_elements(\n",
    "          lambda x: format_instruction_template(x['instruction'], x['context'], x['response']),\n",
    "          return_dtype=pl.Utf8\n",
    "      )\n",
    "      .alias('text')\n",
    "])\n",
    "\n",
    "print(df['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "Eq3h6w_KqMTR",
   "metadata": {
    "id": "Eq3h6w_KqMTR",
    "outputId": "4d33747c-a3ce-450f-cc22-7cf630ce79db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 15,011\n",
      "\n",
      "Calculated split sizes:\n",
      "  Train:      12,008 (80.0%)\n",
      "  Validation: 1,501 (10.0%)\n",
      "  Test:       1,502 (10.0%)\n"
     ]
    }
   ],
   "source": [
    "df_shuffled = df.sample(fraction=1.0, seed=42, shuffle=True)\n",
    "\n",
    "total_size = df_shuffled.height\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "print(f\"Total examples: {total_size:,}\")\n",
    "print(f\"\\nCalculated split sizes:\")\n",
    "print(f\"  Train:      {train_size:,} ({train_size/total_size*100:.1f}%)\")\n",
    "print(f\"  Validation: {val_size:,} ({val_size/total_size*100:.1f}%)\")\n",
    "print(f\"  Test:       {test_size:,} ({test_size/total_size*100:.1f}%)\")\n",
    "\n",
    "\n",
    "train_df = df_shuffled.slice(0, train_size)\n",
    "val_df = df_shuffled.slice(train_size, val_size)\n",
    "test_df = df_shuffled.slice(train_size + val_size, test_size)\n",
    "\n",
    "assert train_df.height + val_df.height + test_df.height == total_size, \"Data loss in split!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QS0K8WESUObg",
   "metadata": {
    "id": "QS0K8WESUObg",
    "outputId": "317ec5ec-3a62-4116-a51b-608158aa1efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "drive_path = '/content/drive/MyDrive/LLaMA2-Dolly-Training/data'\n",
    "os.makedirs(drive_path, exist_ok=True)\n",
    "\n",
    "train_df_storage = train_df.select(['text'])\n",
    "val_df_storage = val_df.select(['text'])\n",
    "test_df_storage = test_df.select(['text'])\n",
    "\n",
    "train_df_storage.write_parquet(f'{drive_path}/train.parquet')\n",
    "val_df_storage.write_parquet(f'{drive_path}/val.parquet')\n",
    "test_df_storage.write_parquet(f'{drive_path}/test.parquet')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}