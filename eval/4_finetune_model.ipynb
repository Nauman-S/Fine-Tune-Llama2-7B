{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2da7a35",
   "metadata": {
    "id": "b2da7a35"
   },
   "source": [
    "# Fine-Tuned Model Inference and Testing\n",
    "\n",
    "## 🎯 Purpose\n",
    "This notebook demonstrates **inference and testing** with our fine-tuned LLaMA-2-7B model. After completing the LoRA fine-tuning process, this notebook loads the trained model and runs it on various inputs to demonstrate the improvements achieved through instruction fine-tuning on the Dolly-15K dataset.\n",
    "\n",
    "## 📊 Evaluation Context\n",
    "Following the complete fine-tuning pipeline:\n",
    "\n",
    "1. **[Baseline Model Evaluation](2_baseline_model.ipynb)** - Established baseline performance metrics\n",
    "2. **[Fine-tuning Process](3_finetuning.ipynb)** - LoRA fine-tuning on Dolly-15K dataset  \n",
    "3. **This Notebook** - Fine-tuned model inference and testing\n",
    "4. **[AlpacaEval Benchmark](5_benchmark_alpaca_eval.ipynb)** - Formal evaluation on AlpacaEval dataset\n",
    "\n",
    "## 🔧 Technical Implementation\n",
    "- **Model**: Fine-tuned LLaMA-2-7B with LoRA adapters loaded from saved checkpoints\n",
    "- **Inference**: Generate responses to various test prompts\n",
    "- **Testing**: Compare fine-tuned model outputs with baseline model\n",
    "- **Evaluation**: Demonstrate improved instruction-following capabilities\n",
    "\n",
    "## 📈 Expected Improvements\n",
    "After LoRA fine-tuning on Dolly-15K, we expect to see:\n",
    "- **Better instruction following** - More accurate responses to user prompts\n",
    "- **Improved formatting** - Consistent response structure and formatting\n",
    "- **Enhanced helpfulness** - More useful and coherent responses\n",
    "- **Better context understanding** - Improved ability to follow complex instructions\n",
    "\n",
    "## 🛠️ Workflow\n",
    "1. **Load fine-tuned model** from saved LoRA adapters\n",
    "2. **Test basic inference** with simple prompts\n",
    "3. **Run on evaluation dataset** to generate responses\n",
    "4. **Compare outputs** with baseline model results\n",
    "5. **Save results** for further analysis and reporting\n",
    "\n",
    "## 🎯 Success Criteria\n",
    "- **Successful model loading** - Fine-tuned weights load correctly\n",
    "- **Improved response quality** - Better instruction following than baseline\n",
    "- **Consistent performance** - Reliable responses across different input types\n",
    "- **Clear improvements** - Demonstrable benefits from fine-tuning\n",
    "\n",
    "---\n",
    "**Note**: This notebook demonstrates the practical application of our fine-tuned model and provides evidence of the effectiveness of our LoRA fine-tuning approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "m4oFyFY-lsKH",
   "metadata": {
    "id": "m4oFyFY-lsKH",
    "outputId": "53d9d604-7ac6-499d-e933-f1f2dbc52c40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tatsu-lab/alpaca_eval.git\n",
      "  Cloning https://github.com/tatsu-lab/alpaca_eval.git to /tmp/pip-req-build-t94pdjug\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/tatsu-lab/alpaca_eval.git /tmp/pip-req-build-t94pdjug\n",
      "  Resolved https://github.com/tatsu-lab/alpaca_eval.git to commit cd543a149df89434d8a54582c0151c0b945c3d20\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.1.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (4.0.0)\n",
      "Requirement already satisfied: openai>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.109.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (2.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (0.12.0)\n",
      "Collecting fire (from alpaca_eval==0.6.6)\n",
      "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.16.2)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (0.35.3)\n",
      "Requirement already satisfied: patsy in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.6.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (2.11.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (4.15.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.3.2->alpaca_eval==0.6.6) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.3.2->alpaca_eval==0.6.6) (2.32.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (2025.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (6.0.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->alpaca_eval==0.6.6) (1.1.10)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->alpaca_eval==0.6.6) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->alpaca_eval==0.6.6) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->alpaca_eval==0.6.6) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->alpaca_eval==0.6.6) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->alpaca_eval==0.6.6) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->alpaca_eval==0.6.6) (3.6.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai>=1.5.0->alpaca_eval==0.6.6) (3.11)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (3.13.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.5.0->alpaca_eval==0.6.6) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.5.0->alpaca_eval==0.6.6) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.5.0->alpaca_eval==0.6.6) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.5.0->alpaca_eval==0.6.6) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.5.0->alpaca_eval==0.6.6) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.5.0->alpaca_eval==0.6.6) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->alpaca_eval==0.6.6) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.3.2->alpaca_eval==0.6.6) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.3.2->alpaca_eval==0.6.6) (2.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (1.22.0)\n",
      "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: alpaca_eval\n",
      "  Building wheel for alpaca_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for alpaca_eval: filename=alpaca_eval-0.6.6-py3-none-any.whl size=362273 sha256=8821dab3535a1f8fc63a66f72dbdfb5cd3caf6af4d35edbe22645d95b32bbbf1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vfegex48/wheels/bf/8d/a9/e0d859ccbf6b8e0cc9e5c1cc9f14e0cc81c3a4880472f7150b\n",
      "Successfully built alpaca_eval\n",
      "Installing collected packages: fire, alpaca_eval\n",
      "Successfully installed alpaca_eval-0.6.6 fire-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/tatsu-lab/alpaca_eval.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "h07iUu5HsCGw",
   "metadata": {
    "id": "h07iUu5HsCGw",
    "outputId": "cd8b063a-69a2-4b7f-b65b-a0200b9d8f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu126)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.10.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
      "Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl (60.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.48.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sXsuyzLGl0R4",
   "metadata": {
    "id": "sXsuyzLGl0R4"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from huggingface_hub import hf_hub_url\n",
    "from peft import PeftModel\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import os\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "_1Ng1KEPmwPX",
   "metadata": {
    "id": "_1Ng1KEPmwPX",
    "outputId": "fa1b3c17-b796-4ad7-93da-527bcaef8033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "uFAb7_j0sd3g",
   "metadata": {
    "id": "uFAb7_j0sd3g",
    "outputId": "7953270a-1947-4ff7-d099-e8f5618be088"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11b0a6912ff4f08bc658b46016b3593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(new_session=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "PU3TQaQHnP2f",
   "metadata": {
    "id": "PU3TQaQHnP2f",
    "outputId": "b96d7dd3-f3bd-4e56-9933-da96e3771124"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5354bf38094bf78549d18bec81025c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ced7ffe22d4c5584bf25a7c963e359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67f691b303f4339a226ee1eed6be6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01a6bac2c3b45ff97ac096302c0a691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d08c089e344012bc2a2f413bfecafa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd794c7116af4290b1c49629c2787d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d61c714edb4fcfa89cc80a5a62a5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fine-Tuned LoRA adapter from: /content/drive/MyDrive/LLaMA2-Dolly-Training/results/final_lora_adapter...\n",
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): LlamaForCausalLM(\n",
      "      (model): LlamaModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=11008, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=11008, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=11008, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (rotary_emb): LlamaRotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Load the fine-tuned model\n",
    "model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "adapter_path = \"/content/drive/MyDrive/LLaMA2-Dolly-Training/results/final_lora_adapter\"\n",
    "print(f\"Loading Fine-Tuned LoRA adapter from: {adapter_path}...\")\n",
    "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_path)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4deZdJ6xoCBJ",
   "metadata": {
    "id": "4deZdJ6xoCBJ",
    "outputId": "30184e78-654e-4712-d0b2-141d4ca15b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of France?\n",
      " nobody knows\n",
      "What is the capital of France?\n",
      "Paris is the capital of France.\n",
      "What is the capital of France? Paris\n",
      "What is the capital of France? Paris\n",
      "What is the capital of France? Paris\n",
      "What\n"
     ]
    }
   ],
   "source": [
    "#Do a simple run with the fine tuned model\n",
    "prompt = \"What is the capital of France\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs = inputs.to(model.device)\n",
    "generate_ids = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=50,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "generated_text = tokenizer.decode(generate_ids[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "VBGPqxzQoiFa",
   "metadata": {
    "id": "VBGPqxzQoiFa",
    "outputId": "def44e49-8df3-4c47-a088-966896f788e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>dataset</th><th>instruction</th><th>output</th><th>generator</th><th>baseline_output</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;koala&quot;</td><td>&quot;in billiards what happens if o…</td><td>&quot;If every striped ball is pocke…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;**f**:\n",
       "\n",
       "```\n",
       "(6)\n",
       "```\n",
       "\n",
       "### Instr…</td></tr><tr><td>&quot;koala&quot;</td><td>&quot;i assume you are familiar with…</td><td>&quot;Estimates and Error Margins:\n",
       "•…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;&lt;img src=&quot;https://i.imgur.com/…</td></tr><tr><td>&quot;selfinstruct&quot;</td><td>&quot;Give students tips on how to k…</td><td>&quot;1. Practice your presentation …</td><td>&quot;text_davinci_003&quot;</td><td>&quot;1. Relax\n",
       "\n",
       "2. Breathe\n",
       "\n",
       "3. Talk …</td></tr><tr><td>&quot;helpful_base&quot;</td><td>&quot;what is the name of chris tuck…</td><td>&quot;Chris Tucker&#x27;s first movie was…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;[The Fifth Element](https://ww…</td></tr><tr><td>&quot;koala&quot;</td><td>&quot;Please summarise in point form…</td><td>&quot;1. Decline in agricultural pro…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;In the article, Devèze summari…</td></tr><tr><td>&quot;helpful_base&quot;</td><td>&quot;I&#x27;m trying to teach myself to …</td><td>&quot;Sure! Here are a few tips to h…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;### Instruction:&quot;</td></tr><tr><td>&quot;koala&quot;</td><td>&quot;cost of fuel for a 14 mile jou…</td><td>&quot;£3.75&quot;</td><td>&quot;text_davinci_003&quot;</td><td>&quot;cost of fuel for a 14 mile jou…</td></tr><tr><td>&quot;koala&quot;</td><td>&quot;Explain me the Finite Elemente…</td><td>&quot;The Finite Element Method (FEM…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;The finite element method (FEM…</td></tr><tr><td>&quot;oasst&quot;</td><td>&quot;How can I use software defined…</td><td>&quot;To detect and locate a drone f…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;The first thing you need to do…</td></tr><tr><td>&quot;selfinstruct&quot;</td><td>&quot;You are given a tweet and you …</td><td>&quot;Offensive&quot;</td><td>&quot;text_davinci_003&quot;</td><td>&quot;Offensive.\n",
       "\n",
       "### Instruction:\n",
       "\n",
       "…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 5)\n",
       "┌──────────────┬─────────────────────┬─────────────────────┬──────────────────┬────────────────────┐\n",
       "│ dataset      ┆ instruction         ┆ output              ┆ generator        ┆ baseline_output    │\n",
       "│ ---          ┆ ---                 ┆ ---                 ┆ ---              ┆ ---                │\n",
       "│ str          ┆ str                 ┆ str                 ┆ str              ┆ str                │\n",
       "╞══════════════╪═════════════════════╪═════════════════════╪══════════════════╪════════════════════╡\n",
       "│ koala        ┆ in billiards what   ┆ If every striped    ┆ text_davinci_003 ┆ **f**:             │\n",
       "│              ┆ happens if o…       ┆ ball is pocke…      ┆                  ┆                    │\n",
       "│              ┆                     ┆                     ┆                  ┆ ```                │\n",
       "│              ┆                     ┆                     ┆                  ┆ (6)                │\n",
       "│              ┆                     ┆                     ┆                  ┆ ```                │\n",
       "│              ┆                     ┆                     ┆                  ┆                    │\n",
       "│              ┆                     ┆                     ┆                  ┆ ### Instr…         │\n",
       "│ koala        ┆ i assume you are    ┆ Estimates and Error ┆ text_davinci_003 ┆ <img src=\"https:// │\n",
       "│              ┆ familiar with…      ┆ Margins:            ┆                  ┆ i.imgur.com/…      │\n",
       "│              ┆                     ┆ •…                  ┆                  ┆                    │\n",
       "│ selfinstruct ┆ Give students tips  ┆ 1. Practice your    ┆ text_davinci_003 ┆ 1. Relax           │\n",
       "│              ┆ on how to k…        ┆ presentation …      ┆                  ┆                    │\n",
       "│              ┆                     ┆                     ┆                  ┆ 2. Breathe         │\n",
       "│              ┆                     ┆                     ┆                  ┆                    │\n",
       "│              ┆                     ┆                     ┆                  ┆ 3. Talk …          │\n",
       "│ helpful_base ┆ what is the name of ┆ Chris Tucker's      ┆ text_davinci_003 ┆ [The Fifth Element │\n",
       "│              ┆ chris tuck…         ┆ first movie was…    ┆                  ┆ ](https://ww…      │\n",
       "│ koala        ┆ Please summarise in ┆ 1. Decline in       ┆ text_davinci_003 ┆ In the article,    │\n",
       "│              ┆ point form…         ┆ agricultural pro…   ┆                  ┆ Devèze summari…    │\n",
       "│ helpful_base ┆ I'm trying to teach ┆ Sure! Here are a    ┆ text_davinci_003 ┆ ### Instruction:   │\n",
       "│              ┆ myself to …         ┆ few tips to h…      ┆                  ┆                    │\n",
       "│ koala        ┆ cost of fuel for a  ┆ £3.75               ┆ text_davinci_003 ┆ cost of fuel for a │\n",
       "│              ┆ 14 mile jou…        ┆                     ┆                  ┆ 14 mile jou…       │\n",
       "│ koala        ┆ Explain me the      ┆ The Finite Element  ┆ text_davinci_003 ┆ The finite element │\n",
       "│              ┆ Finite Elemente…    ┆ Method (FEM…        ┆                  ┆ method (FEM…       │\n",
       "│ oasst        ┆ How can I use       ┆ To detect and       ┆ text_davinci_003 ┆ The first thing    │\n",
       "│              ┆ software defined…   ┆ locate a drone f…   ┆                  ┆ you need to do…    │\n",
       "│ selfinstruct ┆ You are given a     ┆ Offensive           ┆ text_davinci_003 ┆ Offensive.         │\n",
       "│              ┆ tweet and you …     ┆                     ┆                  ┆                    │\n",
       "│              ┆                     ┆                     ┆                  ┆ ### Instruction:   │\n",
       "│              ┆                     ┆                     ┆                  ┆                    │\n",
       "│              ┆                     ┆                     ┆                  ┆ …                  │\n",
       "└──────────────┴─────────────────────┴─────────────────────┴──────────────────┴────────────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"/content/drive/MyDrive/LLaMA2-Dolly-Training/outputs\"\n",
    "baseline_parquet_path = os.path.join(output_dir, \"baseline_model_outputs.parquet\")\n",
    "\n",
    "eval_set_with_baseline = pl.read_parquet(baseline_parquet_path)\n",
    "\n",
    "eval_set_with_baseline.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "HzF5R7dFtD9g",
   "metadata": {
    "id": "HzF5R7dFtD9g",
    "outputId": "dd778baf-594e-4683-eff4-52fe440e1d87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating 10 outputs from fine-tuned model in batches of 1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0024413586914d46bfe243fb153c781d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>dataset</th><th>instruction</th><th>output</th><th>generator</th><th>baseline_output</th><th>finetuned_output</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;koala&quot;</td><td>&quot;in billiards what happens if o…</td><td>&quot;If every striped ball is pocke…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;**f**:\n",
       "\n",
       "```\n",
       "(6)\n",
       "```\n",
       "\n",
       "### Instr…</td><td>&quot;On the break every strip ball …</td></tr><tr><td>&quot;koala&quot;</td><td>&quot;i assume you are familiar with…</td><td>&quot;Estimates and Error Margins:\n",
       "•…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;&lt;img src=&quot;https://i.imgur.com/…</td><td>&quot;The Drake equation gives the f…</td></tr><tr><td>&quot;selfinstruct&quot;</td><td>&quot;Give students tips on how to k…</td><td>&quot;1. Practice your presentation …</td><td>&quot;text_davinci_003&quot;</td><td>&quot;1. Relax\n",
       "\n",
       "2. Breathe\n",
       "\n",
       "3. Talk …</td><td>&quot;- Practice the presentation ma…</td></tr><tr><td>&quot;helpful_base&quot;</td><td>&quot;what is the name of chris tuck…</td><td>&quot;Chris Tucker&#x27;s first movie was…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;[The Fifth Element](https://ww…</td><td>&quot;Friday&quot;</td></tr><tr><td>&quot;koala&quot;</td><td>&quot;Please summarise in point form…</td><td>&quot;1. Decline in agricultural pro…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;In the article, Devèze summari…</td><td>&quot;1. High cost of production\n",
       "2. …</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "┌──────────────┬────────────────┬────────────────┬────────────────┬────────────────┬───────────────┐\n",
       "│ dataset      ┆ instruction    ┆ output         ┆ generator      ┆ baseline_outpu ┆ finetuned_out │\n",
       "│ ---          ┆ ---            ┆ ---            ┆ ---            ┆ t              ┆ put           │\n",
       "│ str          ┆ str            ┆ str            ┆ str            ┆ ---            ┆ ---           │\n",
       "│              ┆                ┆                ┆                ┆ str            ┆ str           │\n",
       "╞══════════════╪════════════════╪════════════════╪════════════════╪════════════════╪═══════════════╡\n",
       "│ koala        ┆ in billiards   ┆ If every       ┆ text_davinci_0 ┆ **f**:         ┆ On the break  │\n",
       "│              ┆ what happens   ┆ striped ball   ┆ 03             ┆                ┆ every strip   │\n",
       "│              ┆ if o…          ┆ is pocke…      ┆                ┆ ```            ┆ ball …        │\n",
       "│              ┆                ┆                ┆                ┆ (6)            ┆               │\n",
       "│              ┆                ┆                ┆                ┆ ```            ┆               │\n",
       "│              ┆                ┆                ┆                ┆                ┆               │\n",
       "│              ┆                ┆                ┆                ┆ ### Instr…     ┆               │\n",
       "│ koala        ┆ i assume you   ┆ Estimates and  ┆ text_davinci_0 ┆ <img src=\"http ┆ The Drake     │\n",
       "│              ┆ are familiar   ┆ Error Margins: ┆ 03             ┆ s://i.imgur.co ┆ equation      │\n",
       "│              ┆ with…          ┆ •…             ┆                ┆ m/…            ┆ gives the f…  │\n",
       "│ selfinstruct ┆ Give students  ┆ 1. Practice    ┆ text_davinci_0 ┆ 1. Relax       ┆ - Practice    │\n",
       "│              ┆ tips on how to ┆ your           ┆ 03             ┆                ┆ the           │\n",
       "│              ┆ k…             ┆ presentation … ┆                ┆ 2. Breathe     ┆ presentation  │\n",
       "│              ┆                ┆                ┆                ┆                ┆ ma…           │\n",
       "│              ┆                ┆                ┆                ┆ 3. Talk …      ┆               │\n",
       "│ helpful_base ┆ what is the    ┆ Chris Tucker's ┆ text_davinci_0 ┆ [The Fifth Ele ┆ Friday        │\n",
       "│              ┆ name of chris  ┆ first movie    ┆ 03             ┆ ment](https:// ┆               │\n",
       "│              ┆ tuck…          ┆ was…           ┆                ┆ ww…            ┆               │\n",
       "│ koala        ┆ Please         ┆ 1. Decline in  ┆ text_davinci_0 ┆ In the         ┆ 1. High cost  │\n",
       "│              ┆ summarise in   ┆ agricultural   ┆ 03             ┆ article,       ┆ of production │\n",
       "│              ┆ point form…    ┆ pro…           ┆                ┆ Devèze         ┆ 2. …          │\n",
       "│              ┆                ┆                ┆                ┆ summari…       ┆               │\n",
       "└──────────────┴────────────────┴────────────────┴────────────────┴────────────────┴───────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = eval_set_with_baseline.get_column(\"instruction\").to_list()\n",
    "finetuned_outputs = []\n",
    "BATCH_SIZE = 1\n",
    "print(f\"\\nGenerating {len(instructions)} outputs from fine-tuned model in batches of {BATCH_SIZE}...\")\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "for i in tqdm(range(0, len(instructions), BATCH_SIZE)):\n",
    "    batch_instructions = instructions[i : i + BATCH_SIZE]\n",
    "    prompts = [PROMPT_TEMPLATE.format(instruction=inst) for inst in batch_instructions]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=1024\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generate_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1024,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    output_tokens = generate_ids[:, inputs.input_ids.shape[1]:]\n",
    "    batch_outputs = tokenizer.batch_decode(output_tokens, skip_special_tokens=True)\n",
    "    finetuned_outputs.extend(batch_outputs)\n",
    "\n",
    "eval_set_complete = eval_set_with_baseline.with_columns(\n",
    "    pl.Series(\"finetuned_output\", finetuned_outputs)\n",
    ")\n",
    "\n",
    "eval_set_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0K7U96IXytaz",
   "metadata": {
    "id": "0K7U96IXytaz",
    "outputId": "b70645a5-b24a-4347-b912-816678c51324"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: koala\n",
      "INSTRUCTION: Explain me the Finite Elemente Method\n",
      "GENERATOR: text_davinci_003\n",
      "OUTPUT:\n",
      " The Finite Element Method (FEM) is an analytical technique used to approximate the solution of differential equations. It divides a region into a large number of small elements, and then uses the properties of those elements to calculate an approximate solution. FEM is used extensively in engineering and science to solve a wide range of problems. It can be used to determine the stresses and displacements in structures and machines, to analyze fluid flow, to predict the behavior of electrical and electronic circuits, and to solve partial differential equations.\n",
      "BASELINE:\n",
      " The finite element method (FEM) is a computational method for solving problems in engineering and mathematical physics.\n",
      "\n",
      "The basic idea behind the finite element method is to divide the domain into small sub-domains, called elements. The\n",
      "function values on the boundary of an element are specified, and the function values inside the element are obtained by\n",
      "solving a set of algebraic equations.\n",
      "\n",
      "The finite element method is a numerical method for solving partial differential equations (PDEs). It is a\n",
      "discretization technique that approximates the solution of a PDE by discretizing it into a set of finite elements,\n",
      "which are small pieces of the domain.\n",
      "\n",
      "The finite element method is a numerical technique for solving partial differential equations (PDEs). It is a\n",
      "discretization technique that approximates the solution of a PDE by discretizing it into a set of finite elements,\n",
      "which are small pieces of the domain.\n",
      "\n",
      "The finite element method is a numerical technique for solving partial differential equations (PDEs). It is a\n",
      "discretization technique that approximates the solution of a PDE by discretizing it into a set of finite elements,\n",
      "which are small pieces of the domain.\n",
      "FINE-TUNED:\n",
      " The Finite Element Method is a numerical method for solving partial differential equations. It is a general method that can be applied to all types of partial differential equations. The method is based on the idea of dividing the problem domain into smaller pieces, called elements. Each element is then discretized, which means that it is divided into smaller pieces, called nodes. The nodes are then connected by edges, and the equations for the nodes are solved using a numerical method. The method is often used in engineering, where it can be used to solve problems that are too complex to solve analytically.\n"
     ]
    }
   ],
   "source": [
    "random_row_with_output = eval_set_complete.sample(n=1)\n",
    "print(f\"DATASET: {random_row_with_output['dataset'][0]}\")\n",
    "print(f\"INSTRUCTION: {random_row_with_output['instruction'][0]}\")\n",
    "print(f\"GENERATOR: {random_row_with_output['generator'][0]}\")\n",
    "print(f\"OUTPUT:\\n {random_row_with_output['output'][0]}\")\n",
    "\n",
    "print(f\"BASELINE:\\n {random_row_with_output['baseline_output'][0]}\")\n",
    "\n",
    "print(f\"FINE-TUNED:\\n {random_row_with_output['finetuned_output'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "XRa38L9qz_yr",
   "metadata": {
    "id": "XRa38L9qz_yr",
    "outputId": "628a45e3-7b31-44c3-e921-f65f0ad6dae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving combined DataFrame (baseline + fine-tuned) to: /content/drive/MyDrive/LLaMA2-Dolly-Training/outputs/eval_outputs_combined.parquet\n",
      "-rw------- 1 root root 14K Oct 19 09:33 /content/drive/MyDrive/LLaMA2-Dolly-Training/outputs/eval_outputs_combined.parquet\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/content/drive/MyDrive/LLaMA2-Dolly-Training/outputs\"\n",
    "combined_parquet_path = os.path.join(output_dir, \"eval_outputs_combined.parquet\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Saving combined DataFrame (baseline + fine-tuned) to: {combined_parquet_path}\")\n",
    "eval_set_complete.write_parquet(combined_parquet_path)\n",
    "!ls -lh \"{combined_parquet_path}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
