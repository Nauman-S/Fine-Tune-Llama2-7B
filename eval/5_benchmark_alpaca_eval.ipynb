{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b2da7a35",
      "metadata": {
        "id": "b2da7a35"
      },
      "source": [
        "# AlpacaEval 2 Benchmark Evaluation\n",
        "\n",
        "##  Purpose\n",
        "This notebook implements **AlpacaEval 2** evaluation to assess instruction-following quality of our fine-tuned LLaMA-2-7B model. This is a critical component of the evaluation framework required by [Assignment 7](../../tasks/Assignment7.md) to demonstrate the effectiveness of our LoRA fine-tuning approach.\n",
        "\n",
        "## Evaluation Context\n",
        "Following the complete fine-tuning pipeline:\n",
        "\n",
        "1. **[Baseline Model Evaluation](baseline_model.ipynb)** - Established baseline performance metrics\n",
        "2. **[Fine-tuning Process](finetune_model.ipynb)** - LoRA fine-tuning on Dolly-15K dataset  \n",
        "3. **This Notebook** - AlpacaEval 2 evaluation of fine-tuned model\n",
        "4. **MT-Bench Evaluation** - Multi-turn dialogue assessment (separate notebook)\n",
        "\n",
        "## AlpacaEval 2 Framework\n",
        "- **Repository**: https://github.com/tatsu-lab/alpaca_eval\n",
        "- **Purpose**: Standardized evaluation dataset for instruction-following models\n",
        "- **Dataset**: 805 diverse instruction-following examples\n",
        "- **Method**: Generate responses with our model, then use automated judge (GPT-4) to compare against reference responses\n",
        "- **Metrics**: Win rate (how often our model's response is preferred over reference)\n",
        "\n",
        "## Expected Improvements\n",
        "After LoRA fine-tuning on Dolly-15K, we expect to see:\n",
        "- **Higher win rates** against reference responses\n",
        "- **Better instruction following** quality\n",
        "- **More helpful and coherent** responses\n",
        "- **Improved formatting** and structure\n",
        "\n",
        "## Technical Implementation\n",
        "- **Model**: Fine-tuned LLaMA-2-7B with LoRA adapters\n",
        "- **Process**:\n",
        "  1. Load our fine-tuned model\n",
        "  2. Generate responses to AlpacaEval dataset instructions\n",
        "  3. Use GPT-4 as automated judge to compare our responses vs. reference responses\n",
        "  4. Calculate win rate (percentage of times our response is preferred)\n",
        "- **Comparison**: Fine-tuned vs. baseline model win rates\n",
        "\n",
        "## Workflow\n",
        "1. **Load fine-tuned model** from saved LoRA adapters\n",
        "2. **Load AlpacaEval dataset** (805 instruction examples)\n",
        "3. **Generate responses** using our fine-tuned model\n",
        "4. **Run automated evaluation** using GPT-4 judge to compare against reference responses\n",
        "5. **Calculate win rate** and compare with baseline model results\n",
        "6. **Document metrics** for final report\n",
        "\n",
        "## Success Criteria\n",
        "- **Higher win rate** than baseline model on AlpacaEval dataset\n",
        "- **Measurable improvement** in instruction-following quality\n",
        "- **Consistent performance** across different instruction types\n",
        "- **Clear evidence** of fine-tuning effectiveness\n",
        "\n",
        "---\n",
        "**Note**: This evaluation is essential for demonstrating that our LoRA fine-tuning approach successfully improves the model's instruction-following capabilities on the Dolly-15K dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/tatsu-lab/alpaca_eval.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx955LKj36E3",
        "outputId": "90c87d8d-a6fe-4b1c-a2a2-b5275d583588"
      },
      "id": "Kx955LKj36E3",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/tatsu-lab/alpaca_eval.git\n",
            "  Cloning https://github.com/tatsu-lab/alpaca_eval.git to /tmp/pip-req-build-ve46jucq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tatsu-lab/alpaca_eval.git /tmp/pip-req-build-ve46jucq\n",
            "  Resolved https://github.com/tatsu-lab/alpaca_eval.git to commit cd543a149df89434d8a54582c0151c0b945c3d20\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.1.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (4.0.0)\n",
            "Requirement already satisfied: openai>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.109.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (2.2.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (0.12.0)\n",
            "Collecting fire (from alpaca_eval==0.6.6)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.16.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (0.35.3)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.6.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (4.15.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.3.2->alpaca_eval==0.6.6) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.3.2->alpaca_eval==0.6.6) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->alpaca_eval==0.6.6) (1.1.10)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->alpaca_eval==0.6.6) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->alpaca_eval==0.6.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->alpaca_eval==0.6.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->alpaca_eval==0.6.6) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->alpaca_eval==0.6.6) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->alpaca_eval==0.6.6) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai>=1.5.0->alpaca_eval==0.6.6) (3.11)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (3.13.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.5.0->alpaca_eval==0.6.6) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.5.0->alpaca_eval==0.6.6) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.5.0->alpaca_eval==0.6.6) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.5.0->alpaca_eval==0.6.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.5.0->alpaca_eval==0.6.6) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.5.0->alpaca_eval==0.6.6) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->alpaca_eval==0.6.6) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.3.2->alpaca_eval==0.6.6) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.3.2->alpaca_eval==0.6.6) (2.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (1.22.0)\n",
            "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: alpaca_eval\n",
            "  Building wheel for alpaca_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alpaca_eval: filename=alpaca_eval-0.6.6-py3-none-any.whl size=362273 sha256=83f909a3de2e6dd66d48bbe3c869cb53d0ceabb5f5988167e204c4ac5ab1f08a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qe8vyhw9/wheels/bf/8d/a9/e0d859ccbf6b8e0cc9e5c1cc9f14e0cc81c3a4880472f7150b\n",
            "Successfully built alpaca_eval\n",
            "Installing collected packages: fire, alpaca_eval\n",
            "Successfully installed alpaca_eval-0.6.6 fire-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import json\n",
        "import os\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "fQT-hU7W4F7o"
      },
      "id": "fQT-hU7W4F7o",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMKMxf-e6c_R",
        "outputId": "4bed1f68-25a0-47b3-b3ea-1e40e0d76385"
      },
      "id": "YMKMxf-e6c_R",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Drive unmounted successfully.\n",
            "Removed existing /content/drive directory.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"/content/drive/MyDrive/LLaMA2-Dolly-Training/outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "combined_parquet_path = os.path.join(output_dir, \"eval_outputs_combined.parquet\")\n",
        "eval_set_complete = pl.read_parquet(combined_parquet_path)\n",
        "print(f\"✓ Loaded {eval_set_complete.height} records.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHVp9VYP4GtI",
        "outputId": "0359a24b-6eaa-4f79-88e0-a36903a5edfa"
      },
      "id": "YHVp9VYP4GtI",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Loaded 10 records.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_for_alpaca_eval(df: pl.DataFrame, output_col_name: str, file_path: str, generator_name: str):\n",
        "    if output_col_name not in df.columns:\n",
        "        print(f\"Error: Column '{output_col_name}' not found in DataFrame.\")\n",
        "        return\n",
        "    if \"instruction\" not in df.columns:\n",
        "        print(\"Error: Column 'instruction' not found in DataFrame.\")\n",
        "        return\n",
        "\n",
        "    # Select columns and add generator name\n",
        "    selected_df = df.select([\n",
        "        \"instruction\",\n",
        "        pl.col(output_col_name).alias(\"output\"),\n",
        "        pl.lit(generator_name).alias(\"generator\")\n",
        "    ])\n",
        "    output_list = selected_df.to_dicts()\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(output_list, f, indent=4, ensure_ascii=False)\n",
        "        print(f\"✓ Saved outputs for AlpacaEval to: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving JSON file '{file_path}': {e}\")"
      ],
      "metadata": {
        "id": "Nz3Y1v-w64gv"
      },
      "id": "Nz3Y1v-w64gv",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_json_path = os.path.join(output_dir, \"alpaca_eval_baseline_outputs.json\")\n",
        "finetuned_json_path = os.path.join(output_dir, \"alpaca_eval_finetuned_outputs.json\")\n",
        "\n",
        "save_for_alpaca_eval(eval_set_complete, \"baseline_output\", baseline_json_path, \"Llama2-7B-Baseline\")\n",
        "save_for_alpaca_eval(eval_set_complete, \"finetuned_output\", finetuned_json_path, \"Llama2-7B-Dolly-QLoRA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8HdqD1v7Tez",
        "outputId": "e43b6ada-d317-4885-ae9a-4de207ac0f19"
      },
      "id": "D8HdqD1v7Tez",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Saved outputs for AlpacaEval to: /content/drive/MyDrive/LLaMA2-Dolly-Training/outputs/alpaca_eval_baseline_outputs.json\n",
            "✓ Saved outputs for AlpacaEval to: /content/drive/MyDrive/LLaMA2-Dolly-Training/outputs/alpaca_eval_finetuned_outputs.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results_path = os.path.join(output_dir, \"eval_results_finetuned_vs_baseline_WeightedGPT4t\")\n",
        "os.makedirs(eval_results_path, exist_ok=True)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"PLACEHOLDER\"\n",
        "!alpaca_eval \\\n",
        "    --model_outputs \"{finetuned_json_path}\" \\\n",
        "    --reference_outputs \"{baseline_json_path}\" \\\n",
        "    --annotators_config \"weighted_alpaca_eval_gpt4_turbo\" \\\n",
        "    --output_path \"{eval_results_path}\" \\\n",
        "    --name \"Llama2-7B-Dolly-QLoRA_vs_Baseline_WeightedGPT4t\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnZR5iRI7izC",
        "outputId": "519a2186-02a4-4539-9d86-70834f2674c3"
      },
      "id": "HnZR5iRI7izC",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:precomputed_leaderboard = 'auto'. But we have found no corresponding leaderboard for /content/drive/MyDrive/LLaMA2-Dolly-Training/outputs/alpaca_eval_baseline_outputs.json and weighted_alpaca_eval_gpt4_turbo\n",
            "INFO:root:Evaluating the Llama2-7B-Dolly-QLoRA_vs_Baseline_WeightedGPT4t outputs.\n",
            "INFO:root:Creating the annotator from `weighted_alpaca_eval_gpt4_turbo`.\n",
            "INFO:root:Saving annotations to `/usr/local/lib/python3.12/dist-packages/alpaca_eval/evaluators_configs/weighted_alpaca_eval_gpt4_turbo/annotations_seed0_configs.json`.\n",
            "INFO:root:Loading all annotations from /usr/local/lib/python3.12/dist-packages/alpaca_eval/evaluators_configs/weighted_alpaca_eval_gpt4_turbo/annotations_seed0_configs.json.\n",
            "Annotation chunk:   0% 0/1 [00:00<?, ?it/s]INFO:root:Annotating 0 examples with weighted_alpaca_eval_gpt4_turbo\n",
            "INFO:root:Saving all annotations to /usr/local/lib/python3.12/dist-packages/alpaca_eval/evaluators_configs/weighted_alpaca_eval_gpt4_turbo/annotations_seed0_configs.json.\n",
            "INFO:root:Loading all annotations from /usr/local/lib/python3.12/dist-packages/alpaca_eval/evaluators_configs/weighted_alpaca_eval_gpt4_turbo/annotations_seed0_configs.json.\n",
            "Annotation chunk: 100% 1/1 [00:00<00:00, 34.48it/s]\n",
            "df_gamed.csv: 149kB [00:00, 46.1MB/s]\n",
            "WARNING:root:Length controlled win rate is very different from the raw one: 87.5% vs 76.7%. This might be a sign of failure of the GLM.\n",
            "INFO:root:Saving all results to /content/drive/MyDrive/LLaMA2-Dolly-Training/outputs/eval_results_finetuned_vs_baseline_WeightedGPT4t/weighted_alpaca_eval_gpt4_turbo\n",
            "INFO:root:Not saving the result to the cached leaderboard because precomputed_leaderboard is not a path but <class 'NoneType'>.\n",
            "                                                 length_controlled_winrate  win_rate  standard_error  n_total  avg_length\n",
            "Llama2-7B-Dolly-QLoRA_vs_Baseline_WeightedGPT4t                      87.49     76.74           13.02       10         167\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}