{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2da7a35",
   "metadata": {
    "id": "b2da7a35"
   },
   "source": [
    "# AlpacaEval 2 Benchmark Evaluation\n",
    "\n",
    "##  Purpose\n",
    "This notebook implements runs on the fine-tuned model. This is a critical component of the evaluation framework required by [Assignment 7](../../tasks/Assignment7.md) to run the model weights on different inputs.\n",
    "\n",
    "## Evaluation Context\n",
    "Following the complete fine-tuning pipeline:\n",
    "\n",
    "1. **[Baseline Model Evaluation](baseline_model.ipynb)** - Established baseline performance metrics\n",
    "2. **[Fine-tuning Process](finetune_model.ipynb)** - LoRA fine-tuning on Dolly-15K dataset  \n",
    "3. **This Notebook** - AlpacaEval 2 evaluation of fine-tuned model\n",
    "4. **MT-Bench Evaluation** - Multi-turn dialogue assessment (separate notebook)\n",
    "\n",
    "## AlpacaEval 2 Framework\n",
    "- **Repository**: https://github.com/tatsu-lab/alpaca_eval\n",
    "- **Purpose**: Standardized evaluation dataset for instruction-following models\n",
    "- **Dataset**: 805 diverse instruction-following examples\n",
    "- **Method**: Generate responses with our model, then use automated judge (GPT-4) to compare against reference responses\n",
    "- **Metrics**: Win rate (how often our model's response is preferred over reference)\n",
    "\n",
    "## Expected Improvements\n",
    "After LoRA fine-tuning on Dolly-15K, we expect to see:\n",
    "- **Higher win rates** against reference responses\n",
    "- **Better instruction following** quality\n",
    "- **More helpful and coherent** responses\n",
    "- **Improved formatting** and structure\n",
    "\n",
    "## Technical Implementation\n",
    "- **Model**: Fine-tuned LLaMA-2-7B with LoRA adapters\n",
    "- **Process**:\n",
    "  1. Load our fine-tuned model\n",
    "  2. Generate responses to AlpacaEval dataset instructions\n",
    "  3. Use GPT-4 as automated judge to compare our responses vs. reference responses\n",
    "  4. Calculate win rate (percentage of times our response is preferred)\n",
    "- **Comparison**: Fine-tuned vs. baseline model win rates\n",
    "\n",
    "## Workflow\n",
    "1. **Load fine-tuned model** from saved LoRA adapters\n",
    "2. **Load AlpacaEval dataset** (805 instruction examples)\n",
    "3. **Generate responses** using our fine-tuned model\n",
    "4. **Run automated evaluation** using GPT-4 judge to compare against reference responses\n",
    "5. **Calculate win rate** and compare with baseline model results\n",
    "6. **Document metrics** for final report\n",
    "\n",
    "## Success Criteria\n",
    "- **Higher win rate** than baseline model on AlpacaEval dataset\n",
    "- **Measurable improvement** in instruction-following quality\n",
    "- **Consistent performance** across different instruction types\n",
    "- **Clear evidence** of fine-tuning effectiveness\n",
    "\n",
    "---\n",
    "**Note**: This evaluation is essential for demonstrating that our LoRA fine-tuning approach successfully improves the model's instruction-following capabilities on the Dolly-15K dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install git+https://github.com/tatsu-lab/alpaca_eval.git"
   ],
   "metadata": {
    "id": "m4oFyFY-lsKH",
    "outputId": "53d9d604-7ac6-499d-e933-f1f2dbc52c40"
   },
   "id": "m4oFyFY-lsKH",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting git+https://github.com/tatsu-lab/alpaca_eval.git\n",
      "  Cloning https://github.com/tatsu-lab/alpaca_eval.git to /tmp/pip-req-build-t94pdjug\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/tatsu-lab/alpaca_eval.git /tmp/pip-req-build-t94pdjug\n",
      "  Resolved https://github.com/tatsu-lab/alpaca_eval.git to commit cd543a149df89434d8a54582c0151c0b945c3d20\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.1.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (4.0.0)\n",
      "Requirement already satisfied: openai>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.109.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (2.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (0.12.0)\n",
      "Collecting fire (from alpaca_eval==0.6.6)\n",
      "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.16.2)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (0.35.3)\n",
      "Requirement already satisfied: patsy in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from alpaca_eval==0.6.6) (1.6.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (2.11.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai>=1.5.0->alpaca_eval==0.6.6) (4.15.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.3.2->alpaca_eval==0.6.6) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.3.2->alpaca_eval==0.6.6) (2.32.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (2025.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets->alpaca_eval==0.6.6) (6.0.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->alpaca_eval==0.6.6) (1.1.10)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->alpaca_eval==0.6.6) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->alpaca_eval==0.6.6) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->alpaca_eval==0.6.6) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->alpaca_eval==0.6.6) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->alpaca_eval==0.6.6) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->alpaca_eval==0.6.6) (3.6.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai>=1.5.0->alpaca_eval==0.6.6) (3.11)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (3.13.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.5.0->alpaca_eval==0.6.6) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.5.0->alpaca_eval==0.6.6) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.5.0->alpaca_eval==0.6.6) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.5.0->alpaca_eval==0.6.6) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.5.0->alpaca_eval==0.6.6) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.5.0->alpaca_eval==0.6.6) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->alpaca_eval==0.6.6) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.3.2->alpaca_eval==0.6.6) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.3.2->alpaca_eval==0.6.6) (2.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->alpaca_eval==0.6.6) (1.22.0)\n",
      "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: alpaca_eval\n",
      "  Building wheel for alpaca_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for alpaca_eval: filename=alpaca_eval-0.6.6-py3-none-any.whl size=362273 sha256=8821dab3535a1f8fc63a66f72dbdfb5cd3caf6af4d35edbe22645d95b32bbbf1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vfegex48/wheels/bf/8d/a9/e0d859ccbf6b8e0cc9e5c1cc9f14e0cc81c3a4880472f7150b\n",
      "Successfully built alpaca_eval\n",
      "Installing collected packages: fire, alpaca_eval\n",
      "Successfully installed alpaca_eval-0.6.6 fire-0.7.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -U transformers peft bitsandbytes"
   ],
   "metadata": {
    "id": "h07iUu5HsCGw",
    "outputId": "cd8b063a-69a2-4b7f-b65b-a0200b9d8f7f"
   },
   "id": "h07iUu5HsCGw",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu126)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.10.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
      "Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl (60.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.48.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from huggingface_hub import hf_hub_url\n",
    "from peft import PeftModel\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import os\n",
    "from google.colab import drive"
   ],
   "metadata": {
    "id": "sXsuyzLGl0R4"
   },
   "id": "sXsuyzLGl0R4",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "drive.mount('/content/drive', force_remount=True)"
   ],
   "metadata": {
    "id": "_1Ng1KEPmwPX",
    "outputId": "fa1b3c17-b796-4ad7-93da-527bcaef8033"
   },
   "id": "_1Ng1KEPmwPX",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from huggingface_hub import login\n",
    "login(new_session=False)"
   ],
   "metadata": {
    "id": "uFAb7_j0sd3g",
    "outputId": "7953270a-1947-4ff7-d099-e8f5618be088"
   },
   "id": "uFAb7_j0sd3g",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a11b0a6912ff4f08bc658b46016b3593"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Load the fine-tuned model\n",
    "model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "adapter_path = \"/content/drive/MyDrive/LLaMA2-Dolly-Training/results/final_lora_adapter\"\n",
    "print(f\"Loading Fine-Tuned LoRA adapter from: {adapter_path}...\")\n",
    "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_path)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "print(model)\n",
    "\n"
   ],
   "metadata": {
    "id": "PU3TQaQHnP2f",
    "outputId": "b96d7dd3-f3bd-4e56-9933-da96e3771124"
   },
   "id": "PU3TQaQHnP2f",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b5354bf38094bf78549d18bec81025c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97ced7ffe22d4c5584bf25a7c963e359"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c67f691b303f4339a226ee1eed6be6b8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e01a6bac2c3b45ff97ac096302c0a691"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78d08c089e344012bc2a2f413bfecafa"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd794c7116af4290b1c49629c2787d63"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45d61c714edb4fcfa89cc80a5a62a5cf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading Fine-Tuned LoRA adapter from: /content/drive/MyDrive/LLaMA2-Dolly-Training/results/final_lora_adapter...\n",
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): LlamaForCausalLM(\n",
      "      (model): LlamaModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=11008, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=11008, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=11008, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (rotary_emb): LlamaRotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Do a simple run with the fine tuned model\n",
    "prompt = \"What is the capital of France\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs = inputs.to(model.device)\n",
    "generate_ids = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=50,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "generated_text = tokenizer.decode(generate_ids[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ],
   "metadata": {
    "id": "4deZdJ6xoCBJ",
    "outputId": "30184e78-654e-4712-d0b2-141d4ca15b02"
   },
   "id": "4deZdJ6xoCBJ",
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "What is the capital of France?\n",
      " nobody knows\n",
      "What is the capital of France?\n",
      "Paris is the capital of France.\n",
      "What is the capital of France? Paris\n",
      "What is the capital of France? Paris\n",
      "What is the capital of France? Paris\n",
      "What\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "output_dir = \"/content/drive/MyDrive/LLaMA2-Dolly-Training/outputs\"\n",
    "baseline_parquet_path = os.path.join(output_dir, \"baseline_model_outputs.parquet\")\n",
    "\n",
    "eval_set_with_baseline = pl.read_parquet(baseline_parquet_path)\n",
    "\n",
    "eval_set_with_baseline.head(10)"
   ],
   "metadata": {
    "id": "VBGPqxzQoiFa",
    "outputId": "def44e49-8df3-4c47-a088-966896f788e6"
   },
   "id": "VBGPqxzQoiFa",
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "shape: (10, 5)\n",
       "┌──────────────┬─────────────────────┬─────────────────────┬──────────────────┬────────────────────┐\n",
       "│ dataset      ┆ instruction         ┆ output              ┆ generator        ┆ baseline_output    │\n",
       "│ ---          ┆ ---                 ┆ ---                 ┆ ---              ┆ ---                │\n",
       "│ str          ┆ str                 ┆ str                 ┆ str              ┆ str                │\n",
       "╞══════════════╪═════════════════════╪═════════════════════╪══════════════════╪════════════════════╡\n",
       "│ koala        ┆ in billiards what   ┆ If every striped    ┆ text_davinci_003 ┆ **f**:             │\n",
       "│              ┆ happens if o…       ┆ ball is pocke…      ┆                  ┆                    │\n",
       "│              ┆                     ┆                     ┆                  ┆ ```                │\n",
       "│              ┆                     ┆                     ┆                  ┆ (6)                │\n",
       "│              ┆                     ┆                     ┆                  ┆ ```                │\n",
       "│              ┆                     ┆                     ┆                  ┆                    │\n",
       "│              ┆                     ┆                     ┆                  ┆ ### Instr…         │\n",
       "│ koala        ┆ i assume you are    ┆ Estimates and Error ┆ text_davinci_003 ┆ <img src=\"https:// │\n",
       "│              ┆ familiar with…      ┆ Margins:            ┆                  ┆ i.imgur.com/…      │\n",
       "│              ┆                     ┆ •…                  ┆                  ┆                    │\n",
       "│ selfinstruct ┆ Give students tips  ┆ 1. Practice your    ┆ text_davinci_003 ┆ 1. Relax           │\n",
       "│              ┆ on how to k…        ┆ presentation …      ┆                  ┆                    │\n",
       "│              ┆                     ┆                     ┆                  ┆ 2. Breathe         │\n",
       "│              ┆                     ┆                     ┆                  ┆                    │\n",
       "│              ┆                     ┆                     ┆                  ┆ 3. Talk …          │\n",
       "│ helpful_base ┆ what is the name of ┆ Chris Tucker's      ┆ text_davinci_003 ┆ [The Fifth Element │\n",
       "│              ┆ chris tuck…         ┆ first movie was…    ┆                  ┆ ](https://ww…      │\n",
       "│ koala        ┆ Please summarise in ┆ 1. Decline in       ┆ text_davinci_003 ┆ In the article,    │\n",
       "│              ┆ point form…         ┆ agricultural pro…   ┆                  ┆ Devèze summari…    │\n",
       "│ helpful_base ┆ I'm trying to teach ┆ Sure! Here are a    ┆ text_davinci_003 ┆ ### Instruction:   │\n",
       "│              ┆ myself to …         ┆ few tips to h…      ┆                  ┆                    │\n",
       "│ koala        ┆ cost of fuel for a  ┆ £3.75               ┆ text_davinci_003 ┆ cost of fuel for a │\n",
       "│              ┆ 14 mile jou…        ┆                     ┆                  ┆ 14 mile jou…       │\n",
       "│ koala        ┆ Explain me the      ┆ The Finite Element  ┆ text_davinci_003 ┆ The finite element │\n",
       "│              ┆ Finite Elemente…    ┆ Method (FEM…        ┆                  ┆ method (FEM…       │\n",
       "│ oasst        ┆ How can I use       ┆ To detect and       ┆ text_davinci_003 ┆ The first thing    │\n",
       "│              ┆ software defined…   ┆ locate a drone f…   ┆                  ┆ you need to do…    │\n",
       "│ selfinstruct ┆ You are given a     ┆ Offensive           ┆ text_davinci_003 ┆ Offensive.         │\n",
       "│              ┆ tweet and you …     ┆                     ┆                  ┆                    │\n",
       "│              ┆                     ┆                     ┆                  ┆ ### Instruction:   │\n",
       "│              ┆                     ┆                     ┆                  ┆                    │\n",
       "│              ┆                     ┆                     ┆                  ┆ …                  │\n",
       "└──────────────┴─────────────────────┴─────────────────────┴──────────────────┴────────────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>dataset</th><th>instruction</th><th>output</th><th>generator</th><th>baseline_output</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;koala&quot;</td><td>&quot;in billiards what happens if o…</td><td>&quot;If every striped ball is pocke…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;**f**:\n",
       "\n",
       "```\n",
       "(6)\n",
       "```\n",
       "\n",
       "### Instr…</td></tr><tr><td>&quot;koala&quot;</td><td>&quot;i assume you are familiar with…</td><td>&quot;Estimates and Error Margins:\n",
       "•…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;&lt;img src=&quot;https://i.imgur.com/…</td></tr><tr><td>&quot;selfinstruct&quot;</td><td>&quot;Give students tips on how to k…</td><td>&quot;1. Practice your presentation …</td><td>&quot;text_davinci_003&quot;</td><td>&quot;1. Relax\n",
       "\n",
       "2. Breathe\n",
       "\n",
       "3. Talk …</td></tr><tr><td>&quot;helpful_base&quot;</td><td>&quot;what is the name of chris tuck…</td><td>&quot;Chris Tucker&#x27;s first movie was…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;[The Fifth Element](https://ww…</td></tr><tr><td>&quot;koala&quot;</td><td>&quot;Please summarise in point form…</td><td>&quot;1. Decline in agricultural pro…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;In the article, Devèze summari…</td></tr><tr><td>&quot;helpful_base&quot;</td><td>&quot;I&#x27;m trying to teach myself to …</td><td>&quot;Sure! Here are a few tips to h…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;### Instruction:&quot;</td></tr><tr><td>&quot;koala&quot;</td><td>&quot;cost of fuel for a 14 mile jou…</td><td>&quot;£3.75&quot;</td><td>&quot;text_davinci_003&quot;</td><td>&quot;cost of fuel for a 14 mile jou…</td></tr><tr><td>&quot;koala&quot;</td><td>&quot;Explain me the Finite Elemente…</td><td>&quot;The Finite Element Method (FEM…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;The finite element method (FEM…</td></tr><tr><td>&quot;oasst&quot;</td><td>&quot;How can I use software defined…</td><td>&quot;To detect and locate a drone f…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;The first thing you need to do…</td></tr><tr><td>&quot;selfinstruct&quot;</td><td>&quot;You are given a tweet and you …</td><td>&quot;Offensive&quot;</td><td>&quot;text_davinci_003&quot;</td><td>&quot;Offensive.\n",
       "\n",
       "### Instruction:\n",
       "\n",
       "…</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "instructions = eval_set_with_baseline.get_column(\"instruction\").to_list()\n",
    "finetuned_outputs = []\n",
    "BATCH_SIZE = 1\n",
    "print(f\"\\nGenerating {len(instructions)} outputs from fine-tuned model in batches of {BATCH_SIZE}...\")\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "for i in tqdm(range(0, len(instructions), BATCH_SIZE)):\n",
    "    batch_instructions = instructions[i : i + BATCH_SIZE]\n",
    "    prompts = [PROMPT_TEMPLATE.format(instruction=inst) for inst in batch_instructions]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=1024\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generate_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1024,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    output_tokens = generate_ids[:, inputs.input_ids.shape[1]:]\n",
    "    batch_outputs = tokenizer.batch_decode(output_tokens, skip_special_tokens=True)\n",
    "    finetuned_outputs.extend(batch_outputs)\n",
    "\n",
    "eval_set_complete = eval_set_with_baseline.with_columns(\n",
    "    pl.Series(\"finetuned_output\", finetuned_outputs)\n",
    ")\n",
    "\n",
    "eval_set_complete.head()"
   ],
   "metadata": {
    "id": "HzF5R7dFtD9g",
    "outputId": "dd778baf-594e-4683-eff4-52fe440e1d87"
   },
   "id": "HzF5R7dFtD9g",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Generating 10 outputs from fine-tuned model in batches of 1...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0024413586914d46bfe243fb153c781d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "shape: (5, 6)\n",
       "┌──────────────┬────────────────┬────────────────┬────────────────┬────────────────┬───────────────┐\n",
       "│ dataset      ┆ instruction    ┆ output         ┆ generator      ┆ baseline_outpu ┆ finetuned_out │\n",
       "│ ---          ┆ ---            ┆ ---            ┆ ---            ┆ t              ┆ put           │\n",
       "│ str          ┆ str            ┆ str            ┆ str            ┆ ---            ┆ ---           │\n",
       "│              ┆                ┆                ┆                ┆ str            ┆ str           │\n",
       "╞══════════════╪════════════════╪════════════════╪════════════════╪════════════════╪═══════════════╡\n",
       "│ koala        ┆ in billiards   ┆ If every       ┆ text_davinci_0 ┆ **f**:         ┆ On the break  │\n",
       "│              ┆ what happens   ┆ striped ball   ┆ 03             ┆                ┆ every strip   │\n",
       "│              ┆ if o…          ┆ is pocke…      ┆                ┆ ```            ┆ ball …        │\n",
       "│              ┆                ┆                ┆                ┆ (6)            ┆               │\n",
       "│              ┆                ┆                ┆                ┆ ```            ┆               │\n",
       "│              ┆                ┆                ┆                ┆                ┆               │\n",
       "│              ┆                ┆                ┆                ┆ ### Instr…     ┆               │\n",
       "│ koala        ┆ i assume you   ┆ Estimates and  ┆ text_davinci_0 ┆ <img src=\"http ┆ The Drake     │\n",
       "│              ┆ are familiar   ┆ Error Margins: ┆ 03             ┆ s://i.imgur.co ┆ equation      │\n",
       "│              ┆ with…          ┆ •…             ┆                ┆ m/…            ┆ gives the f…  │\n",
       "│ selfinstruct ┆ Give students  ┆ 1. Practice    ┆ text_davinci_0 ┆ 1. Relax       ┆ - Practice    │\n",
       "│              ┆ tips on how to ┆ your           ┆ 03             ┆                ┆ the           │\n",
       "│              ┆ k…             ┆ presentation … ┆                ┆ 2. Breathe     ┆ presentation  │\n",
       "│              ┆                ┆                ┆                ┆                ┆ ma…           │\n",
       "│              ┆                ┆                ┆                ┆ 3. Talk …      ┆               │\n",
       "│ helpful_base ┆ what is the    ┆ Chris Tucker's ┆ text_davinci_0 ┆ [The Fifth Ele ┆ Friday        │\n",
       "│              ┆ name of chris  ┆ first movie    ┆ 03             ┆ ment](https:// ┆               │\n",
       "│              ┆ tuck…          ┆ was…           ┆                ┆ ww…            ┆               │\n",
       "│ koala        ┆ Please         ┆ 1. Decline in  ┆ text_davinci_0 ┆ In the         ┆ 1. High cost  │\n",
       "│              ┆ summarise in   ┆ agricultural   ┆ 03             ┆ article,       ┆ of production │\n",
       "│              ┆ point form…    ┆ pro…           ┆                ┆ Devèze         ┆ 2. …          │\n",
       "│              ┆                ┆                ┆                ┆ summari…       ┆               │\n",
       "└──────────────┴────────────────┴────────────────┴────────────────┴────────────────┴───────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>dataset</th><th>instruction</th><th>output</th><th>generator</th><th>baseline_output</th><th>finetuned_output</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;koala&quot;</td><td>&quot;in billiards what happens if o…</td><td>&quot;If every striped ball is pocke…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;**f**:\n",
       "\n",
       "```\n",
       "(6)\n",
       "```\n",
       "\n",
       "### Instr…</td><td>&quot;On the break every strip ball …</td></tr><tr><td>&quot;koala&quot;</td><td>&quot;i assume you are familiar with…</td><td>&quot;Estimates and Error Margins:\n",
       "•…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;&lt;img src=&quot;https://i.imgur.com/…</td><td>&quot;The Drake equation gives the f…</td></tr><tr><td>&quot;selfinstruct&quot;</td><td>&quot;Give students tips on how to k…</td><td>&quot;1. Practice your presentation …</td><td>&quot;text_davinci_003&quot;</td><td>&quot;1. Relax\n",
       "\n",
       "2. Breathe\n",
       "\n",
       "3. Talk …</td><td>&quot;- Practice the presentation ma…</td></tr><tr><td>&quot;helpful_base&quot;</td><td>&quot;what is the name of chris tuck…</td><td>&quot;Chris Tucker&#x27;s first movie was…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;[The Fifth Element](https://ww…</td><td>&quot;Friday&quot;</td></tr><tr><td>&quot;koala&quot;</td><td>&quot;Please summarise in point form…</td><td>&quot;1. Decline in agricultural pro…</td><td>&quot;text_davinci_003&quot;</td><td>&quot;In the article, Devèze summari…</td><td>&quot;1. High cost of production\n",
       "2. …</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "random_row_with_output = eval_set_complete.sample(n=1)\n",
    "print(f\"DATASET: {random_row_with_output['dataset'][0]}\")\n",
    "print(f\"INSTRUCTION: {random_row_with_output['instruction'][0]}\")\n",
    "print(f\"GENERATOR: {random_row_with_output['generator'][0]}\")\n",
    "print(f\"OUTPUT:\\n {random_row_with_output['output'][0]}\")\n",
    "\n",
    "print(f\"BASELINE:\\n {random_row_with_output['baseline_output'][0]}\")\n",
    "\n",
    "print(f\"FINE-TUNED:\\n {random_row_with_output['finetuned_output'][0]}\")"
   ],
   "metadata": {
    "id": "0K7U96IXytaz",
    "outputId": "b70645a5-b24a-4347-b912-816678c51324"
   },
   "id": "0K7U96IXytaz",
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DATASET: koala\n",
      "INSTRUCTION: Explain me the Finite Elemente Method\n",
      "GENERATOR: text_davinci_003\n",
      "OUTPUT:\n",
      " The Finite Element Method (FEM) is an analytical technique used to approximate the solution of differential equations. It divides a region into a large number of small elements, and then uses the properties of those elements to calculate an approximate solution. FEM is used extensively in engineering and science to solve a wide range of problems. It can be used to determine the stresses and displacements in structures and machines, to analyze fluid flow, to predict the behavior of electrical and electronic circuits, and to solve partial differential equations.\n",
      "BASELINE:\n",
      " The finite element method (FEM) is a computational method for solving problems in engineering and mathematical physics.\n",
      "\n",
      "The basic idea behind the finite element method is to divide the domain into small sub-domains, called elements. The\n",
      "function values on the boundary of an element are specified, and the function values inside the element are obtained by\n",
      "solving a set of algebraic equations.\n",
      "\n",
      "The finite element method is a numerical method for solving partial differential equations (PDEs). It is a\n",
      "discretization technique that approximates the solution of a PDE by discretizing it into a set of finite elements,\n",
      "which are small pieces of the domain.\n",
      "\n",
      "The finite element method is a numerical technique for solving partial differential equations (PDEs). It is a\n",
      "discretization technique that approximates the solution of a PDE by discretizing it into a set of finite elements,\n",
      "which are small pieces of the domain.\n",
      "\n",
      "The finite element method is a numerical technique for solving partial differential equations (PDEs). It is a\n",
      "discretization technique that approximates the solution of a PDE by discretizing it into a set of finite elements,\n",
      "which are small pieces of the domain.\n",
      "FINE-TUNED:\n",
      " The Finite Element Method is a numerical method for solving partial differential equations. It is a general method that can be applied to all types of partial differential equations. The method is based on the idea of dividing the problem domain into smaller pieces, called elements. Each element is then discretized, which means that it is divided into smaller pieces, called nodes. The nodes are then connected by edges, and the equations for the nodes are solved using a numerical method. The method is often used in engineering, where it can be used to solve problems that are too complex to solve analytically.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "output_dir = \"/content/drive/MyDrive/LLaMA2-Dolly-Training/outputs\"\n",
    "combined_parquet_path = os.path.join(output_dir, \"eval_outputs_combined.parquet\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Saving combined DataFrame (baseline + fine-tuned) to: {combined_parquet_path}\")\n",
    "eval_set_complete.write_parquet(combined_parquet_path)\n",
    "!ls -lh \"{combined_parquet_path}\""
   ],
   "metadata": {
    "id": "XRa38L9qz_yr",
    "outputId": "628a45e3-7b31-44c3-e921-f65f0ad6dae4"
   },
   "id": "XRa38L9qz_yr",
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving combined DataFrame (baseline + fine-tuned) to: /content/drive/MyDrive/LLaMA2-Dolly-Training/outputs/eval_outputs_combined.parquet\n",
      "-rw------- 1 root root 14K Oct 19 09:33 /content/drive/MyDrive/LLaMA2-Dolly-Training/outputs/eval_outputs_combined.parquet\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}